{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implement vision trasnformers on CIFAR 10 dataset using pretrained checkpoints.\n",
        "\n",
        "Exponential LR: $\\eta_t=\\eta_0 . \\gamma^t$, where $\\eta_t$ is learning rate in iteration $t$. $\\gamma$ is decay factor like $\\gamma=0.95$.  "
      ],
      "metadata": {
        "id": "SbvATvIesCQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "#import torchmetrics\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vit_b_16\n",
        "from torchvision.models import ViT_B_16_Weights"
      ],
      "metadata": {
        "id": "JKp667JVyKSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbtSyHHCyrGj",
        "outputId": "c3b8a41c-0497-4934-8d7c-2a994e3103d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu128)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.21.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Subset\n",
        "# Define transformations (normalization, augmentation, etc.)\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# Split training set into training (45,000) and validation (5,000)\n",
        "# train_size = int(0.9 * len(trainset))  # 90% for training\n",
        "# val_size = len(trainset) - train_size  # 10% for validation\n",
        "# train_subset, val_subset = random_split(trainset, [train_size, val_size])\n",
        "subset_size = 20000\n",
        "train_subset = Subset(trainset, list(range(subset_size)))\n",
        "\n",
        "val_subset = Subset(trainset, list(range(subset_size, subset_size + 5000)))\n",
        "\n",
        "\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True, num_workers=0) #Uses 4 separate worker threads to load batches faster.\n",
        "val_loader = DataLoader(val_subset, batch_size=16, shuffle=False, num_workers=0)\n",
        "\n",
        "test_loader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=0)\n"
      ],
      "metadata": {
        "id": "R3-19POrzGme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, optimizer, train_loader, val_loader, device, scheduler):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)  #to track training accuracy\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):   #iterate over small batches\n",
        "            model.train()\n",
        "\n",
        "            ### FORWARD AND BACK PROP\n",
        "            features, targets = features.to(device), targets.to(device)\n",
        "            logits = model(features)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            loss.backward()\n",
        "\n",
        "            ### UPDATE MODEL PARAMETERS\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad() #reset the gradients of all model parameters\n",
        "\n",
        "            ### LOGGING\n",
        "            if not batch_idx % 300:\n",
        "                print(f\"Epoch: {epoch+1:04d}/{num_epochs:04d} | Batch {batch_idx:04d}/{len(train_loader):04d} | Loss: {loss:.4f}\")\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                predicted_labels = torch.argmax(logits, 1)\n",
        "                train_acc.update(predicted_labels, targets)\n",
        "        scheduler.step()\n",
        "\n",
        "        ### MORE LOGGING\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "            for (features, targets) in val_loader:\n",
        "                features, targets = features.to(device), targets.to(device)\n",
        "                outputs = model(features)\n",
        "                predicted_labels = torch.argmax(outputs, 1)\n",
        "                val_acc.update(predicted_labels, targets)\n",
        "\n",
        "            print(f\"Epoch: {epoch+1:04d}/{num_epochs:04d} | Train acc.: {train_acc.compute()*100:.2f}% | Val acc.: {val_acc.compute()*100:.2f}%\")\n",
        "            train_acc.reset(), val_acc.reset()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaCcqnHG5Y5K",
        "outputId": "a00c2eaa-8ada-43f2-aa5a-22e97e8697ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  _C._set_float32_matmul_precision(precision)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #########################################\n",
        "    ### 2 Initializing the Model\n",
        "    #########################################\n",
        "\n",
        "model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1) #16 (Patch Size) → The input image is divided into 16×16 pixel patches.\n"
      ],
      "metadata": {
        "id": "gCn3nZTz5pNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   # replace output layer\n",
        "model.heads.head = torch.nn.Linear(in_features=768, out_features=10)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)  #too large learning rate destroys the pretrained features\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)  #after every epoch, learning rate decays by 10%.\n"
      ],
      "metadata": {
        "id": "pOo0hkjH55fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    #########################################\n",
        "    ### 3 Finetuning\n",
        "    #########################################\n",
        "torch.cuda.empty_cache()\n",
        "start = time.time() #measure total training time\n",
        "train(\n",
        "    num_epochs=3,\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    scheduler=scheduler\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end-start\n",
        "print(f\"Time elapsed {elapsed/60:.2f} min\")\n",
        "print(f\"Memory used: {torch.cuda.max_memory_reserved() / 1e9:.02f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx2P8GW55_bo",
        "outputId": "c34f1337-cd7a-4592-dfa8-394fb516c7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001/0003 | Batch 0000/1250 | Loss: 2.2799\n",
            "Epoch: 0001/0003 | Batch 0300/1250 | Loss: 0.3184\n",
            "Epoch: 0001/0003 | Batch 0600/1250 | Loss: 0.1237\n",
            "Epoch: 0001/0003 | Batch 0900/1250 | Loss: 0.1196\n",
            "Epoch: 0001/0003 | Batch 1200/1250 | Loss: 0.0695\n",
            "Epoch: 0001/0003 | Train acc.: 91.65% | Val acc.: 92.60%\n",
            "Epoch: 0002/0003 | Batch 0000/1250 | Loss: 0.0629\n",
            "Epoch: 0002/0003 | Batch 0300/1250 | Loss: 0.0073\n",
            "Epoch: 0002/0003 | Batch 0600/1250 | Loss: 0.7606\n",
            "Epoch: 0002/0003 | Batch 0900/1250 | Loss: 0.2015\n",
            "Epoch: 0002/0003 | Batch 1200/1250 | Loss: 0.1817\n",
            "Epoch: 0002/0003 | Train acc.: 96.61% | Val acc.: 94.10%\n",
            "Epoch: 0003/0003 | Batch 0000/1250 | Loss: 0.0058\n",
            "Epoch: 0003/0003 | Batch 0300/1250 | Loss: 0.0166\n",
            "Epoch: 0003/0003 | Batch 0600/1250 | Loss: 0.0373\n",
            "Epoch: 0003/0003 | Batch 0900/1250 | Loss: 0.0544\n",
            "Epoch: 0003/0003 | Batch 1200/1250 | Loss: 0.1013\n",
            "Epoch: 0003/0003 | Train acc.: 97.97% | Val acc.: 95.16%\n",
            "Time elapsed 40.23 min\n",
            "Memory used: 3.29 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "    ### 4 Evaluation\n",
        "    #########################################\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "    for (features, targets) in test_loader:\n",
        "        features, targets = features.to(device), targets.to(device)\n",
        "        outputs = model(features)\n",
        "        predicted_labels = torch.argmax(outputs, 1)\n",
        "        test_acc.update(predicted_labels, targets)\n",
        "\n",
        "print(f\"Test accuracy {test_acc.compute()*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPyvqry0_Ap7",
        "outputId": "730f2f09-97d1-4596-9872-3a5c52a1e8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy 95.03%\n"
          ]
        }
      ]
    }
  ]
}